{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "from glob import glob\n",
    "from math import sqrt\n",
    "from dateutil import tz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Global variables\n",
    "latExtent = [22.16,22.5277]\n",
    "lonExtent = [113.816, 114.442]\n",
    "\n",
    "cellCount = [41, 64]\n",
    "cellSizeCoord = [0.01, 0.009]\n",
    "\n",
    "def obs_data(Pollutant, Date_time):\n",
    "    date_list = [(datetime.strptime(Date_time, '%Y-%m-%d %H:%M:%S') + timedelta(hours=x)).strftime('%Y-%m-%d %H:%M:%S') for x in range(0,13)]\n",
    "    df = pd.read_csv('cache/obs/Obs_data.csv', usecols=['time',Pollutant, 'x', 'y']).rename(columns={Pollutant: \"Pollutant\"})\n",
    "    df = df[df['time'].isin(date_list)]\n",
    "    grouped = df.groupby(['time'])\n",
    "    d = {}\n",
    "    for index, group_item in enumerate(grouped):\n",
    "        lis = []\n",
    "        for i in group_item[1].iterrows():\n",
    "            dic = {}\n",
    "            dic['Pollutant'], dic['x'], dic['y'] = i[1]['Pollutant'], i[1]['x'], i[1]['y']\n",
    "            lis.append(dic)\n",
    "        d[index] = lis\n",
    "    return json.dumps(d)\n",
    "\n",
    "# Getting the coordinate range for plotting the map\n",
    "def coordinate_data():\n",
    "    Features = []\n",
    "    coordinate_list = [[37,13], [34,13], [33,14], [40,14], [31,22], [41,17], [55,34], [35,18], \n",
    "                   [34,19], [37,24], [13,14], [45,17], [16,25], [35,32], [30,23], [21,31]]\n",
    "    for i in range(0,cellCount[0]):\n",
    "        cell_y = i\n",
    "        for j in range(0, cellCount[1]):\n",
    "            rect ={\"type\": 'polygon', \"x\": None ,\"y\": None , \"coord\":[]}\n",
    "            cell_x =j\n",
    "            bottomLeft = [latExtent[0] + cellSizeCoord[1]*i, lonExtent[0] + cellSizeCoord[0]*j]\n",
    "            bottomRight = [bottomLeft[0], bottomLeft[1] + cellSizeCoord[0]]\n",
    "            topLeft = [bottomLeft[0]+ cellSizeCoord[1], bottomLeft[1]]\n",
    "            topRight = [bottomRight[0]+ cellSizeCoord[1],bottomRight[1]]\n",
    "            coords = [bottomLeft, bottomRight, topRight, topLeft]\n",
    "            if [cell_x, cell_y] in coordinate_list:\n",
    "                rect[\"x\"], rect[\"y\"], rect[\"coord\"], rect['data'] = cell_x, cell_y, coords, 'Observatory_data'\n",
    "            else:\n",
    "                rect[\"x\"], rect[\"y\"], rect[\"coord\"], rect['data'] = cell_x, cell_y, coords, 'Grid_data'\n",
    "            Features.append(rect)\n",
    "    return json.dumps(Features)\n",
    "\n",
    "def get_data(date, Pollutant):\n",
    "    month = [datetime.strptime(date, '%Y-%m-%d %H:%M:%S').month]\n",
    "    dic = {}\n",
    "    for i in ['CMAQ', 'Our_method'] :\n",
    "        directory = os.path.join('data','cache',i,Pollutant)\n",
    "        data, filename = month_data(month, directory)\n",
    "        diff = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')-datetime.strptime(filename[:-4], '%Y-%m-%d %H:%M:%S')\n",
    "        hours = diff.days * 24 + diff.seconds // 3600\n",
    "        dic[i] = data[hours].tolist()\n",
    "    return json.dumps(dic)      \n",
    "       \n",
    "def time_poldata(pol_data, start_date):\n",
    "    time_data = np.load('cache/time_data.npy')\n",
    "    df = pd.DataFrame(time_data, columns = ['time'])\n",
    "    df = df[df.time >= str(start_date)]\n",
    "    data = {}\n",
    "    for i,j in zip(df.iterrows(),pol_data):\n",
    "        data[i[1]['time']] = j\n",
    "    return data\n",
    "\n",
    "def month_data(month_list, direc):\n",
    "    final_data = []\n",
    "    for file in os.listdir(direc):\n",
    "        if file.endswith('.npy') and datetime.strptime(file[:-4], '%Y-%m-%d %H:%M:%S').month in month_list:\n",
    "            data = np.load(os.path.join(direc,file))\n",
    "            final_data.append(data)\n",
    "    return np.concatenate(final_data), file\n",
    "\n",
    "# Getting the metrics value \n",
    "def metrics(df_1, df_2):\n",
    "    act = df_1['Pollutant'].values\n",
    "    pred = df_2['Pollutant'].values\n",
    "#     rmse = round(sqrt(mean_squared_error(act, pred)),2)\n",
    "    ioa = round(1 -(np.sum((act-pred)**2))/(np.sum((np.abs(pred-np.mean(act))+np.abs(act-np.mean(act)))**2)), 2)\n",
    "    return 1, ioa\n",
    "\n",
    "# Station code with coordinates\n",
    "def station_coord(key):\n",
    "    d= {'CB_R': [37,13], \n",
    "        'CL_R': [34,13],\n",
    "        'CW_A': [33,14],\n",
    "        'EN_A': [40,14],\n",
    "        'KC_A': [31,22],\n",
    "        'KT_A': [41,17],\n",
    "        'MB_A': [55,34],\n",
    "        'MKaR': [35,18],\n",
    "        'SP_A': [34,19],\n",
    "        'ST_A': [37,24],\n",
    "        'TC_A': [13,14],\n",
    "        'TK_A': [45,17],\n",
    "        'TM_A': [16,25],\n",
    "        'TP_A': [35,32],\n",
    "        'TW_A': [30,23],\n",
    "        'YL_A': [21,31]}\n",
    "    return d[key]\n",
    "\n",
    "def obs_onsite_data(path, code, Pollutant, date_list):\n",
    "    df = pd.read_csv(path, usecols=['time', 'station_code', Pollutant]).rename(columns={Pollutant: \"Pollutant\"})\n",
    "    df = df[((df[\"time\"].isin(date_list)) & (df[\"station_code\"] == code))].drop(['station_code'], axis=1)\n",
    "    df['data'] = 'station_data'\n",
    "    return df\n",
    "\n",
    "def arguments(dt):\n",
    "    start_date = dt['st_date']\n",
    "    end_date = dt['en_date']\n",
    "    Future_hour = dt['F_hour']\n",
    "\n",
    "    st_date = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S') - timedelta(hours=int(Future_hour))\n",
    "    en_date = datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S') - timedelta(hours=int(Future_hour))\n",
    "    delta = en_date - st_date\n",
    "    hours = delta.days * 24 + delta.seconds // 3600\n",
    "    date_list = [str(datetime.strptime(start_date,'%Y-%m-%d %H:%M:%S') + timedelta(hours=i)) for i in range(hours +1)]\n",
    "    date_list_1 = [str(st_date + timedelta(hours=i)) for i in range(hours +1)]\n",
    "    return st_date, en_date, date_list, date_list_1, Future_hour\n",
    "\n",
    "def line_chart_1(dt, station_type):\n",
    "    Pollutant = dt['pollutant']\n",
    "    code = dt['St_code']\n",
    "\n",
    "    data = []\n",
    "    metric = {}\n",
    "    st_date, en_date, date_list, date_list_1, Future_hour = arguments(dt)\n",
    "    station_df = obs_onsite_data('cache/obs/'+ station_type +'.csv', code, Pollutant, date_list)\n",
    "    data.append(station_df)\n",
    "    for i in ['CMAQ']:\n",
    "        directory = os.path.join('cache',i,Pollutant)\n",
    "        month = [st_date.month, en_date.month]\n",
    "        coords = station_coord(code)\n",
    "        final_data, filename = month_data(month,directory)\n",
    "        whole_data = time_poldata(final_data, st_date)\n",
    "        pol_lis = [whole_data[x][int(Future_hour)][coords[0]][coords[1]] for x in date_list_1]\n",
    "        method_data = pd.DataFrame({'time': date_list, 'Pollutant': pol_lis, 'data': i+'_data'})\n",
    "        data.append(method_data)\n",
    "        RMSE, IOA = metrics(method_data, station_df)\n",
    "        metric['RMSE_'+i], metric['IOA_'+i] =  RMSE, IOA\n",
    "    df = pd.concat(data)\n",
    "    result = df.to_dict('records')\n",
    "    return json.dumps([{'RMSE': metric['RMSE_CMAQ'] , 'IOA': metric['IOA_CMAQ'], 'line_data': result}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = {'st_date' : '2017-02-03 21:00:00', 'en_date' : '2017-02-03 23:00:00', 'F_hour' : '5', 'St_code' : 'CB_R', 'pollutant': 'PM10'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"RMSE\": 1, \"IOA\": 0.36, \"line_data\": [{\"time\": \"2017-02-03 16:00:00\", \"Pollutant\": 39.0, \"data\": \"station_data\"}, {\"time\": \"2017-02-03 17:00:00\", \"Pollutant\": 47.0, \"data\": \"station_data\"}, {\"time\": \"2017-02-03 18:00:00\", \"Pollutant\": 45.0, \"data\": \"station_data\"}, {\"time\": \"2017-02-03 16:00:00\", \"Pollutant\": 67.6698226928711, \"data\": \"CMAQ_data\"}, {\"time\": \"2017-02-03 17:00:00\", \"Pollutant\": 54.082603454589844, \"data\": \"CMAQ_data\"}, {\"time\": \"2017-02-03 18:00:00\", \"Pollutant\": 41.53458786010742, \"data\": \"CMAQ_data\"}]}]'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_chart_1(dt, 'Obs_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"RMSE\": 1, \"IOA\": 0.82, \"line_data\": [{\"time\": \"2017-02-03 21:00:00\", \"Pollutant\": 43.0, \"data\": \"station_data\"}, {\"time\": \"2017-02-03 22:00:00\", \"Pollutant\": 38.0, \"data\": \"station_data\"}, {\"time\": \"2017-02-03 23:00:00\", \"Pollutant\": 42.0, \"data\": \"station_data\"}, {\"time\": \"2017-02-03 21:00:00\", \"Pollutant\": 41.578826904296875, \"data\": \"CMAQ_data\"}, {\"time\": \"2017-02-03 22:00:00\", \"Pollutant\": 38.367488861083984, \"data\": \"CMAQ_data\"}, {\"time\": \"2017-02-03 23:00:00\", \"Pollutant\": 45.064449310302734, \"data\": \"CMAQ_data\"}]}]'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_chart_1(dt, 'Obs_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arguments(dt):\n",
    "    start_date = dt['st_date']\n",
    "    end_date = dt['en_date']\n",
    "    Future_hour = dt['F_hour']\n",
    "\n",
    "    st_date = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S') - timedelta(hours=int(Future_hour))\n",
    "    en_date = datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S') - timedelta(hours=int(Future_hour))\n",
    "    delta = en_date - st_date\n",
    "    hours = delta.days * 24 + delta.seconds // 3600\n",
    "    date_list = [str(datetime.strptime(start_date,'%Y-%m-%d %H:%M:%S') + timedelta(hours=i)) for i in range(hours +1)]\n",
    "    date_list_1 = [str(st_date + timedelta(hours=i)) for i in range(hours +1)]\n",
    "    return st_date, en_date, date_list, date_list_1, Future_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2017, 2, 3, 16, 0),\n",
       " datetime.datetime(2017, 2, 3, 18, 0),\n",
       " ['2017-02-03 21:00:00', '2017-02-03 22:00:00', '2017-02-03 23:00:00'],\n",
       " ['2017-02-03 16:00:00', '2017-02-03 17:00:00', '2017-02-03 18:00:00'],\n",
       " '5')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
